<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[TTimeline]]></title>
  <subtitle><![CDATA[星辰大海]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://tongsucn.com/"/>
  <updated>2015-12-14T20:25:29.000Z</updated>
  <id>http://tongsucn.com/</id>
  
  <author>
    <name><![CDATA[Tong Su]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[[ML Review] Probability Distributions and Conjugate Prior]]></title>
    <link href="http://tongsucn.com/2015/12/07/TODO-ML-Review-Probability-Distributions-and-Conjugate-Prior/"/>
    <id>http://tongsucn.com/2015/12/07/TODO-ML-Review-Probability-Distributions-and-Conjugate-Prior/</id>
    <published>2015-12-07T10:50:20.000Z</published>
    <updated>2015-12-14T20:25:29.000Z</updated>
    <content type="html"><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript" async src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

<h2 id="Introduction">Introduction</h2><p>In the <a href="/2015/11/24/ML-Review-Regression-from-Probability-Perspective/">Bayesian curve fitting</a>, I mentioned that the Gaussian noise assumption (likelihood) and prior Gaussian distribution over weighting vector will result in a Gaussian posterior. The likelihood and prior are conjugate, the prior is also called the conjugate prior.</p>
<h2 id="About_Conjugate_Prior">About Conjugate Prior</h2><p>In general, we will meet the following probabilities: \( p(\theta) : prior, p(\theta | X) : posterior, p(X), p(X | \theta) : likelihood \). According to the Bayes’ Theorem, they could be written as:</p>
<p>$$<br>posterior = \frac{likelihood \times prior} {p(X)}<br>$$</p>
<p>To make the posterior calculation intuitive, we often need that the posterior and the prior have the same “form” (just like in Bayesian curve fitting both of them are Gaussian). Furthermore, the posterior could also be used as the prior of future calculation, which will result in a “calculating chain”:</p>
<p>$$<br>\begin{align}<br>posterior_1 &amp; = \frac{likelihood \times prior} {p(X)} \\<br>posterior_2 &amp; = \frac{likelihood^{‘} \times posterior_1} {p(X^{‘})} \\<br>&amp; …<br>\end{align}<br>$$</p>
<p>If there exists a suitable form of <strong>likelihood</strong>, which make the <strong>posterior</strong> have the same form like <strong>prior</strong>, then the <strong>prior</strong> and <strong>likelihood</strong> are conjugate. That is, conjugate is about the <strong>PRIOR</strong> and the <strong>LIKELIHOOD</strong>.</p>
<p>Previously we used the Gaussian noise assumption (likelihood) and a prior Gaussian distribution. So what about the situations with different noise distributions? In this post I will review them and conclude their conjugate prior.</p>
<h2 id="Probability_Distributions">Probability Distributions</h2><p>There are three kinds of distributions will be introduced in the following sections. They are the binary distribution (Bernoulli distribution, Binomial distribution and Beta distribution), multinomial distribution (Dirichlet distribution) and continuous distribution (Gaussian distribution, Gamma distribution and Student’s t distribution).</p>
<h3 id="Bernoulli,_Binomial_and_Beta_Distribution">Bernoulli, Binomial and Beta Distribution</h3><p>One of the most simplest probability distribution is the Bernoulli distribution, which could be expressed by flipping a coin. The random variable \( x \in \{ 0, 1 \} \), where \( x = 1 \) means head and \( x = 0 \) means tail. The question now is “what is the probability of flipping this coin and getting head as result?” We can denote it by \( \mu \):</p>
<p>$$<br>p(x = 1 | \mu) = \mu<br>$$</p>
<p>Therefore the Bernoulli distribution over \(x\) is written as:</p>
<p>$$<br>\begin{align}<br>\text{Bern}(x | \mu) &amp; = \mu^{x}(1 - \mu)^{1 - x} \\<br>\mathbb{E}[x] &amp; = \mu \\<br>\text{var}[x] &amp; = \mu (1 - \mu)<br>\end{align}<br>$$</p>
<p>Bernoulli distribution describes the single coin situation. The Binomial distribution goes further. It describes the probability distribution of \(N\) coins flipping. The question becomes “the probability of flipping a coin for \(N\) times and \(m\) times of which are head-up in the end”:</p>
<p>$$<br>\begin{align}<br>\text{Bin}(m | N, \mu) &amp; = \left( \begin{array}{c} N \\ m \end{array} \right) \mu^{m} (1 - \mu)^{N - m} \\<br>\mathbb{E}[m] &amp; \equiv \sum_{m = 0}^{N} {m\text{Bin}(m | N, \mu) = N \mu} \\<br>\text{var}[m] &amp; \equiv \sum_{m = 0}^{N} {(m - \mathbb{E}[m])^2 \text{Bin} (m | N, \mu)} = N \mu (1 - \mu)<br>\end{align}<br>$$</p>
<p>It is obvious that Bernoulli distribution is a special case of the Binomial distribution (\(N = 1\)). If we draw a histogram for Binomial distribution \(\text{Bin}(m | 10, 0.25)\), it looks like:</p>
<p>img src=”<a href="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]RPDCP_1.png" target="_blank" rel="external">http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]RPDCP_1.png</a>“ width=”256”&gt;</p>
<p>Now, given a set of observation \( \mathcal{D} = \{ x_1, …, x_M \} \), where each \( x_i, i \in \{1, …, M\} \), is the flipping result (\(0\) for tail-up, \(1\) for head-up). To predict new input and avoid overfitting, we could employ Bayesian estimation (rather than maximum likelihood). The likelihood is:</p>
<p>$$<br>p(\mathcal{D} | \mu) \propto \prod_{m = 1}^{M} {\mu^{x_m} (1 - \mu)^{1 - x_m}}<br>$$</p>
<p>For the reasons mentioned above, we need to find out a prior distribution which has the same function form (conjugate prior) like this:</p>
<p>$$<br>p(\mu | a, b) \propto \mu^{a} (1 - \mu)^{b}<br>$$</p>
<p>This can be related to the Beta Distribution:</p>
<p>$$<br>\begin{align}<br>\text{Beta}(\mu | a, b) &amp; = \frac{\Gamma (a + b)} {\Gamma (a) \Gamma (b)} \mu^{a - 1} (1 - \mu)^{b - 1} \\<br>\Gamma (x) &amp; \equiv \int_{0}^{\infty} {u^{x - 1} e^{-u}} \text{d}u \\<br>\mathbb{E}[\mu] &amp; = \frac{a} {a + b} \\<br>\text{var}[\mu] &amp; = \frac{ab} {(a + b)^{2} (a + b + a)}<br>\end{align}<br>$$</p>
<p>\(\Gamma (x)\) is the <a href="https://en.wikipedia.org/wiki/Gamma_function" target="_blank" rel="external">gamma function</a>, it can also be written as factorial function \( \Gamma (n + 1) = n! = n \Gamma (n) \) when the input is a positive integer. \(a\) and \(b\) are often called hyperparameters. The Beta distribution looks like this:</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Beta_distribution_pdf.svg/531px-Beta_distribution_pdf.svg.png" width="256"></p>
<p>Now let’s apply it with Bayesian approach. \( \mathcal{D} = \{x_1, …, x_M\} \):</p>
<p>$$<br>\begin{align}<br>p(\mu | a_0, b_0, \mathcal{D}) &amp; \propto p(\mathcal{D} | \mu) p(\mu | a_0, b_0) \\<br>&amp; = \left( \prod_{n - 1}^{M} {\mu^{x_n} (1 - \mu)^{1 - x_n}} \right) \text{Beta} (\mu | a_0, b_0) \\<br>&amp; \propto \mu^{m + a_0 - 1} (1 - \mu)^{(M - m) + b_0 - 1} \\<br>&amp; \propto \text{Beta}(\mu | a_M, b_M)<br>\end{align}<br>$$</p>
<p>where \(m\) means the number of head-up results, and \( a_M = a_0 + m, b_M = b_0 +(M - m) \). And we can easily find that hyperparameters \(a\) and \(b\) are actually the effective number of observations for head-up (\(x = 1\)) and tail-up (\(x = 0\)) respectively. Because the posterior is in form of Beta distribution and has the same form with the prior we have just used, it can also be utilized as a prior when new observed data come. As the size of observed data set increases (\(M\) increases):</p>
<p>$$<br>\begin{align}<br>a_M &amp; \rightarrow m \\<br>b_M &amp; \rightarrow M - m \\<br>\mathbb{E}[\mu] &amp; \rightarrow \frac{m}{M} = \mu_{ML} \\<br>\text{var}[\mu] &amp; \rightarrow 0<br>\end{align}<br>$$</p>
<p>“What is the probability that the next coin toss will land heads up?” is the question of prediction:</p>
<p>$$<br>\begin{align}<br>p(x = 1 | a_0, b_0, \mathcal{D}) &amp; = \int_{0}^{1} {p(x = 1 | \mu) p(\mu | a_0, b_0, \mathcal{D})} \text{d} \mu \\<br>&amp; = \int_{0}^{1} {\mu p(\mu | a_0, b_0, \mathcal{D})} \text{d} \mu \\<br>&amp; = \mathbb{E}[\mu | a_0, b_0, \mathcal{D}] = \frac{a_N}{a_N + b_N}<br>\end{align}<br>$$</p>
<p>Therefore it’s equivalent to the total fraction of observations that correspond to \(x = 1\).</p>
<h3 id="Multinomial_and_Dirichlet_Distribution">Multinomial and Dirichlet Distribution</h3><p>Let’s now consider a more complex situation, tossing a dice instead of flipping a coin. Things get complicated because there are potential six results now, they are 1, 2, 3, 4, 5, 6. For convenient we use 1-of-\(K\) coding scheme, here the \(K\) is 6: \( \text{x} = (0, 0, 1, 0, 0, 0)^T \). After generalization, the distribution of \(\text{x}\) with \(K\) outcomes is:</p>
<p>$$<br>p(\text{x} | \mu) = \prod_{k = 1}^{K} {\mu_k^{x_k}}, where \forall k : \mu_k \geq 0 \wedge \sum_{k = 1}^{K} {\mu_k = 1}<br>$$</p>
<p>So the multinomial distribution is also the generalization of the Bernoulli distribution. \(\mu_k\) is the probability of result \(k\). Given a data set \(\mathcal{D} = \{\text{x}_1, …, \text{x}_M\}\), the likelihood:</p>
<p>$$<br>p(\mathcal{D} | \mu) = \prod_{n = 1}^M {\prod_{k = 1}^K {\mu^{x_{nk}}}} = \prod_{k = 1}^K {\mu_k^{(\sum_n {x_{nk}})}}<br>$$</p>
<h3 id="Gaussian_Distribution">Gaussian Distribution</h3><h3 id="Gamma_Distribution">Gamma Distribution</h3><h3 id="Student’s_t_Distribution">Student’s t Distribution</h3><h3 id="More:_Exponential_Family">More: Exponential Family</h3><h2 id="Summary">Summary</h2><p>Prior distributions and their conjugate prior.<br>|Likelihood Function|Conjugate Prior|<br>|:—:|:—:|<br>|Bernoulli|Beta distribution|</p>
<h2 id="Reference">Reference</h2><p>[1] <a href="https://en.wikipedia.org/wiki/Conjugate_prior" target="_blank" rel="external">Conjugate Prior</a><br>[2] Bishop, Christopher M. Pattern recognition and machine learning. springer, 2006.<br>[3] <a href="https://commons.wikimedia.org/wiki/File:Beta_distribution_pdf.svg#/media/File:Beta_distribution_pdf.svg" target="_blank" rel="external">“Beta distribution pdf” by Horas based on the work of Krishnavedala</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript]]>
    </summary>
    
      <category term="Bernoulli distribution" scheme="http://tongsucn.com/tags/Bernoulli-distribution/"/>
    
      <category term="Beta distribution" scheme="http://tongsucn.com/tags/Beta-distribution/"/>
    
      <category term="Binomial distribution" scheme="http://tongsucn.com/tags/Binomial-distribution/"/>
    
      <category term="Dirichlet distribution" scheme="http://tongsucn.com/tags/Dirichlet-distribution/"/>
    
      <category term="Gamma distribution" scheme="http://tongsucn.com/tags/Gamma-distribution/"/>
    
      <category term="Gaussian distribution" scheme="http://tongsucn.com/tags/Gaussian-distribution/"/>
    
      <category term="Student&#39;s t distribution" scheme="http://tongsucn.com/tags/Student-s-t-distribution/"/>
    
      <category term="binary distribution" scheme="http://tongsucn.com/tags/binary-distribution/"/>
    
      <category term="conjugate distribution" scheme="http://tongsucn.com/tags/conjugate-distribution/"/>
    
      <category term="conjugate prior" scheme="http://tongsucn.com/tags/conjugate-prior/"/>
    
      <category term="continuous distribution" scheme="http://tongsucn.com/tags/continuous-distribution/"/>
    
      <category term="likelihood" scheme="http://tongsucn.com/tags/likelihood/"/>
    
      <category term="machine learning" scheme="http://tongsucn.com/tags/machine-learning/"/>
    
      <category term="multinomial distribution" scheme="http://tongsucn.com/tags/multinomial-distribution/"/>
    
      <category term="posterior" scheme="http://tongsucn.com/tags/posterior/"/>
    
      <category term="prior" scheme="http://tongsucn.com/tags/prior/"/>
    
      <category term="probability distribution" scheme="http://tongsucn.com/tags/probability-distribution/"/>
    
      <category term="tech" scheme="http://tongsucn.com/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[ML Review] Linear Basis Function Models]]></title>
    <link href="http://tongsucn.com/2015/11/28/ML-Review-Linear-Basis-Function-Models/"/>
    <id>http://tongsucn.com/2015/11/28/ML-Review-Linear-Basis-Function-Models/</id>
    <published>2015-11-28T10:18:52.000Z</published>
    <updated>2015-11-28T14:18:00.000Z</updated>
    <content type="html"><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript" async src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

<h2 id="Introduction">Introduction</h2><p>In the previous posts, We have met two linear basis functions: polynomial basis function and Fourier basis function. In this one, I will review and summary them and try making some comparison. The following basis functions are implemented in <a href="https://github.com/tongsucn/MachineLearningPractice/blob/master/Regression/lbasis.py" target="_blank" rel="external">python code</a>.</p>
<h2 id="Polynomial_Basis_Function">Polynomial Basis Function</h2><p>$$<br>\phi_{poly} (x) = (\phi_{0} (x), …, \phi_{M - 1} (x))^T<br>$$</p>
<p>where</p>
<p>$$<br>\phi_{i} (x) = x^{i}, i \in \{0, …, M - 1\}<br>$$</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]LBFM_1.png" ,="" width="256"></p>
<h2 id="Gaussian_Basis_Function">Gaussian Basis Function</h2><p>$$<br>\phi_{gaussian} (x) = (\phi_{0} (x), …, \phi_{M - 1} (x))^T<br>$$</p>
<p>where</p>
<p>$$<br>\phi_{i} (x) = \exp \left\{ - \frac{(x - \mu_{i})^{2}} {2 s^{2}} \right\}, i \in \{0, …, M - 1\}<br>$$</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]LBFM_2.png" ,="" width="256"></p>
<h2 id="Fourier_Basis_Function">Fourier Basis Function</h2><p>$$<br>\phi_{fourier} (x) = (\phi_{0} (x), …, \phi_{2M} (x))^T<br>$$</p>
<p>where</p>
<p>$$<br>\begin{align} \phi_{0} (x) &amp; = 1 \\ \phi_{2n - 1} (x) &amp; = \frac{\cos{(2 \pi nx)}} {n} \\ \phi_{2n} (x) &amp; = \frac{\sin{(2 \pi nx)}} {n},  n \in \{1, …, M\} \end{align}<br>$$</p>
<p>\(\mu_{i}\) and \(s\) control the function’s location and scale (width).</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]LBFM_3.png" ,="" width="256"></p>
<h2 id="Sigmoid_Basis_Function">Sigmoid Basis Function</h2><p>$$<br>\phi_{sigmoid} (x) = (\phi_{0} (x), …, \phi_{M - 1} (x))^T<br>$$</p>
<p>where</p>
<p>$$<br>\begin{align} \phi_{i} (x) &amp; = \sigma \left( \frac{x - \mu_{i}} {s} \right), i \in \{0, …, M - 1\}\\ \sigma (a) &amp; = \frac{1} {1 + \exp (a)} \end{align}<br>$$</p>
<p>\(\mu_{i}\) and \(s\) control the function’s location and scale (slope).</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]LBFM_4.png" ,="" width="256"></p>
<h2 id="Summary">Summary</h2><p>[1] <a href="https://github.com/tongsucn/MachineLearningPractice/blob/master/Regression/lbasis.py" target="_blank" rel="external">Python code</a><br>[2] <a href="http://www.vision.rwth-aachen.de/teaching/advanced-machine-learning/winter-15-16/advanced-machine-learning" target="_blank" rel="external">Lectures</a><br>[3] <a href="https://en.wikipedia.org/wiki/Basis_function" target="_blank" rel="external">Basis Function</a><br>[4] Bishop, Christopher M. Pattern recognition and machine learning. springer, 2006.</p>
]]></content>
    <summary type="html">
    <![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript]]>
    </summary>
    
      <category term="basis function" scheme="http://tongsucn.com/tags/basis-function/"/>
    
      <category term="fourier basis function" scheme="http://tongsucn.com/tags/fourier-basis-function/"/>
    
      <category term="gaussian basis function" scheme="http://tongsucn.com/tags/gaussian-basis-function/"/>
    
      <category term="machine learning" scheme="http://tongsucn.com/tags/machine-learning/"/>
    
      <category term="polynomial basis function" scheme="http://tongsucn.com/tags/polynomial-basis-function/"/>
    
      <category term="sigmoid basis function" scheme="http://tongsucn.com/tags/sigmoid-basis-function/"/>
    
      <category term="blog" scheme="http://tongsucn.com/categories/blog/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[ML Review] Bayesian Curve Regression]]></title>
    <link href="http://tongsucn.com/2015/11/24/ML-Review-Bayesian-Curve-Fitting/"/>
    <id>http://tongsucn.com/2015/11/24/ML-Review-Bayesian-Curve-Fitting/</id>
    <published>2015-11-24T09:44:20.000Z</published>
    <updated>2015-12-14T17:02:54.000Z</updated>
    <content type="html"><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript" async src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

<h2 id="Introduction">Introduction</h2><p>Based on the <a href="/2015/11/24/ML-Review-Regression-from-Probability-Perspective/">previous post</a>, we will go deeper into regression from probability perspective in this post.</p>
<p><img src="http://i3.kym-cdn.com/photos/images/newsfeed/000/531/557/a88.jpg"></p>
<p>In LSR and RR, our training results are some single values of weighting vector \( \text{w} \), with which we can predict new input points simply by using basis function and dot product. The RR works already quite well, but the value selection of regularization coefficient is really intractable. To deal with this challenge, Bayesian curve fitting could help.</p>
<h2 id="Linear_Regression_in_Bayesian_Approach">Linear Regression in Bayesian Approach</h2><h3 id="Training">Training</h3><p>Following is the training phase of Bayesian Curve Fitting. Given a training set \( \text{X} = \{ \text{x}_{1}, …, \text{x}_{N} \} \), relative labels \( \text{t} = \{ t_{1}, …, t_{N} \} \) and the prior distribution hyperparameter (Gaussian here) \( \alpha = (m_0, S_0) \), specifying a suitable basis function \( \phi \). Our goal is the distribution of the weighting vector:</p>
<ol>
<li><p>Calculating the optimized weighting vector \( \text{w}_{opt} \) with LSR:</p>
<p> $$<br> \text{w}_{opt} = \left( \phi(\text{X}) \phi(\text{X})^T \right )^{-1} \phi(\text{X}) \text{t}<br> $$</p>
</li>
<li><p>Calculating the precision \( \beta \):</p>
<p> $$<br> \frac{1} {\beta} = \frac{1} {N} \sum_{n = 1}^{N} {[t_n - \text{w}_{opt}^T \phi(\text{x}_{n}) ]^2}<br> $$</p>
</li>
<li><p>Calculating the MAP solution of \( \hat{\text{w}} \):</p>
<p> $$<br> \hat{\text{w}} = \left( \beta \phi(\text{X}) \phi(\text{X})^T + {S_{0}}^{-1} \text{I} \right)^{-1} \left( \beta \phi(\text{X})^T \text{t} + {S_{0}}^{-1} m_{0} \right)<br> $$</p>
<p> For simplifying the calculation, we often assume that the mean \( m_0 \) in hyperparameter is \( 0 \):</p>
<p> $$<br> \hat{\text{w}} = \left( \beta \phi(\text{X}) \phi(\text{X})^T + {S_{0}}^{-1} \text{I} \right)^{-1} \beta \phi(\text{X})^T \text{t}<br> $$</p>
</li>
<li><p>Calculating the posterior distribution:</p>
<p> We have assumed the Gaussian noise (likelihood) and a prior Gaussian distribution over weighting vector. These will result in a Gaussian posterior distribution over the result weighting vector \( \hat{\text{w}} \), because our prior and likelihood here are conjugate. The prior is also called <a href="https://en.wikipedia.org/wiki/Conjugate_prior" target="_blank" rel="external">conjugate prior</a>. In this post I don’t want to explain it, which could make you puzzled. But it will be introduced in some future posts.</p>
<p> OK let’s go back to our training phase. The MAP solution \( \hat{\text{w}} \) is still a single value. Think about it: our posterior distribution is Gaussian, so this \( \hat{\text{w}} \) should be the mean \( m_N \) of the posterior distribution! It indicates the maximum value in this multivariable Gaussian distribution, because it is the optimized result from MAP. Therefore:</p>
<p> $$ m_N = \hat{\text{w}} $$</p>
<p> And the covariance matrix:</p>
<p> $$ S_N = \left( \beta \phi(\text{X}) \phi(\text{X})^T + {S_{0}}^{-1} \text{I} \right)^{-1} $$</p>
</li>
</ol>
<h3 id="Predictive_Distribution">Predictive Distribution</h3><p>So far, the training phase is finished. But wait, the weighting vector is now actually a distribution, how can we predict an input point with a distribution? According to Mr. Bishop’s book <em>Pattern Recognition and Machine Learning</em> (PRML), the answer is calculating the integral (continuous) / summation (discrete) over \( \text{w} \)’s distribution!</p>
<p>$$<br>p(t | x, \text{X}, \text{t}) = \int { p(t | x, \text{w}) p(\text{w} | \text{X}, \text{t}, \beta, \alpha) \text{dw} }<br>$$</p>
<p>\( p(t | x, \text{w}) = \mathcal{N} (t | y(x, \text{w}), \beta^{-1})\) describes the Gaussian noise distribution and \( p(\text{w} | \text{X}, \text{t}, \beta, \alpha) = \mathcal{N} (\text{w} | m_N, S_N)\) is the MAP solution. Then the posterior distribution is a Gaussian and can be evaluated analytically. According to the PRML, the result is:</p>
<p>$$<br>p(t | x, \text{X}, \text{t}) = \mathcal{N} (t | m(x), s^2(x))<br>$$</p>
<p>where mean and variance are</p>
<p>$$<br>m(x) = \beta \phi(x)^T \text{S} \phi(X) \text{t} \\<br>s(x)^2 = \beta^{-1} + \phi(x) \text{S} \phi(x)<br>$$</p>
<p>and \( \text{S} \) is the regularized covariance matrix:</p>
<p>$$<br>\text{S} = S_N = (\beta \phi(X) \phi(X)^T + S_{0}^{-1} \text{I})^{-1}<br>$$</p>
<p>To be noticed is that both of the mean and the variance depend on the input point. It means that the input points could also affect the distribution. Let me show you an example. The <a href="https://github.com/tongsucn/MachineLearningPractice/blob/master/Regression/poly_data_gaussian_noise.txt" target="_blank" rel="external">data</a> I have prepared is not quite good, so I highly recommend you read the example on PRML.</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]BCR_1.png" ,="" width="256"></p>
<p>This example illustrates a simulated procedure of training (but our training is not implemented like this). The blue curve is our optimized result. The two black thiner curves show the variance \(s(x)\) of every points on the blue curve. They have been rescaled suitably to make them visible, so for example it <strong>DOES NOT</strong> mean that the point at \(x = 0\) has variance about \(1.25\).</p>
<p>It is obvious that in the first figure the variances at the points are quite low, and other places are relative higher. With more points inserted, the variances become “well-distributed”. (Remember I have adjust the scale to make the black curves visible, so the variances of the first two points in the rest two figures look higher than in the first figure).</p>
<h2 id="Summary">Summary</h2><p>In this post we reviewed the Bayesian Curve Fitting. Bayesian is quite general and intuitive, what we need are just the training set and a prior. But unfortunately, <em>in general, it could be impossible or impractical to derive the posterior distribution analytically</em>. However, it is still possible to approximate the posterior by approximate Bayesian inference methods, which will be reviewed in the future.</p>
<p>Furthermore, the Gaussian noise and a Gaussian prior distribution over weighting vector are assumed here. That is, there could exist other distribution combinations. Or we can say under other noise distribution assumptions, we may should change the prior distribution. In the future I would also review some other distribution and relative conjugate priors. Hope it could help :D</p>
<h2 id="Reference">Reference</h2><p>[1] <a href="https://github.com/tongsucn/MachineLearningPractice/blob/master/Regression/poly_data_gaussian_noise.txt" target="_blank" rel="external">data</a><br>[2] <a href="https://en.wikipedia.org/wiki/Conjugate_prior" target="_blank" rel="external">Conjugate Prior</a><br>[3] <a href="https://en.wikipedia.org/wiki/Bayesian_linear_regression" target="_blank" rel="external">Bayesian Linear Regression</a><br>[4] Bishop, Christopher M. Pattern recognition and machine learning. springer, 2006.</p>
]]></content>
    <summary type="html">
    <![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript]]>
    </summary>
    
      <category term="Bayesian" scheme="http://tongsucn.com/tags/Bayesian/"/>
    
      <category term="Bayesian Curve Fitting" scheme="http://tongsucn.com/tags/Bayesian-Curve-Fitting/"/>
    
      <category term="Bayesian Linear Regression" scheme="http://tongsucn.com/tags/Bayesian-Linear-Regression/"/>
    
      <category term="Gaussian distribution" scheme="http://tongsucn.com/tags/Gaussian-distribution/"/>
    
      <category term="conjugate prior" scheme="http://tongsucn.com/tags/conjugate-prior/"/>
    
      <category term="likelihood" scheme="http://tongsucn.com/tags/likelihood/"/>
    
      <category term="machine learning" scheme="http://tongsucn.com/tags/machine-learning/"/>
    
      <category term="maximum likelihood" scheme="http://tongsucn.com/tags/maximum-likelihood/"/>
    
      <category term="maximum-a-posteriori" scheme="http://tongsucn.com/tags/maximum-a-posteriori/"/>
    
      <category term="posterior" scheme="http://tongsucn.com/tags/posterior/"/>
    
      <category term="prior" scheme="http://tongsucn.com/tags/prior/"/>
    
      <category term="probability" scheme="http://tongsucn.com/tags/probability/"/>
    
      <category term="regression" scheme="http://tongsucn.com/tags/regression/"/>
    
      <category term="tech" scheme="http://tongsucn.com/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[ML Review] Regression from Probabilistic Perspective]]></title>
    <link href="http://tongsucn.com/2015/11/24/ML-Review-Regression-from-Probability-Perspective/"/>
    <id>http://tongsucn.com/2015/11/24/ML-Review-Regression-from-Probability-Perspective/</id>
    <published>2015-11-24T09:22:20.000Z</published>
    <updated>2015-11-24T14:11:41.000Z</updated>
    <content type="html"><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript" async src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

<h2 id="Introduction">Introduction</h2><p>I have reviewed the <a href="/2015/11/05/ML-Review-Least-Squares-Regression/">Least Squares Regression</a> (LSR) and <a href="/2015/11/11/ML-Review-Ridge-Regression-and-Regularization/">Ridge Regression</a> (RR). In this post, I will review them again, but from probabilistic perspective.</p>
<h2 id="Probabilistic_Interpretation:_LSR">Probabilistic Interpretation: LSR</h2><p>In LSR and RR, we optimized the results by minimizing the error (sum of squares error was utilized). We can find the training error cannot be 0, it’s not quite precise. This is because in general, the data sets contain noise. Therefore, if we want to consider the LSR and RR from probability perspective, we could use probability to express those noise. For example, given a training set, let’s assume the noise of points in this set have the Gaussian distribution like this (The Gaussian distribution curve has been adjusted for better appearance):</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]RPP_1.png" width="256"></p>
<p>Our target function values \( t \) is now:</p>
<p>$$<br>t = \widetilde{\text{w}}^T \widetilde{\text{x}} + \epsilon = y(\text{x}, \text{w}) + \epsilon<br>$$</p>
<p>\( \epsilon \) here is the noise, which has Gaussian distribution, \( y(\text{x}, \text{w}) \) is the target curve (or ideally we can say it’s the curve without error). Transforming it into probability form, for every single point \( \text{x} \) it will look like:</p>
<p>$$<br>p(t | \text{x}, \text{w}, \beta) = \mathcal{N} (t | y(\text{x}, \text{w}), \beta^{-1})<br>$$</p>
<p>It means that given a point \( \text{x} \), relative weighting vector \( \text{w} \) and the precision parameter \( \beta \) (talk about it later), the target value \( t \) has Gaussian distribution. Therefore, to learn the weighting vector \( \text{w}\) and \( \beta \), we can just maximize the conditional likelihood with the training set \( \text{X} \) and its label set \( \text{t}\):</p>
<p>$$<br>p(\text{t} | \text{X}, \text{w}, \beta) = \prod_{n = 1}^{N} {\mathcal{N} (t_n | y(\text{x}_n, \text{w}), \beta^{-1})}<br>$$</p>
<p>For simplifying the calculation, writing it in \( \log \) form:</p>
<p>$$<br>\begin{align} \log{p(\text{t} | \text{X}, \text{w}, \beta)} &amp; = \sum_{n = 1}^{N} {\log{\mathcal{N} (t_n | y(\text{x}_n, \text{w}), \beta^{-1})}} \\ &amp; = \sum_{n = 1}^{N} { \left[\log{( \sqrt{\frac{\beta} {2 \pi}})} - \frac{\beta} {2} \{ y(\text{w}_n, \text{w}) - t_n \}^2 \right] } \\ &amp; = \frac{N} {2} \log{\beta} - \frac{N} {2} \log{(2 \pi)} - \frac{\beta} {2} \sum_{n = 1}^{N} \{ t_n - y(\text{x}_n, \text{w}) \} \end{align}<br>$$</p>
<p>where \( \frac{N} {2} \log{\beta} - \frac{N} {2} \log{(2 \pi)} \) is a constant, and the rest is the sum of squares error. Calculating its Gradient w.r.t \( \text{w} \) we can get:</p>
<p>$$<br>\begin{align} \nabla_{\text{w}} \log {p(\text{t} | \text{X}, \text{w}, \beta)} &amp; = - \beta \sum_{n = 1}^{N} {(t_n - \text{w}^T \phi(\text{x}_n)) \phi(\text{x}_n)} \stackrel{!}{=} 0 \\ &amp; \Rightarrow \sum_{n - 1}^{N} {t_n \phi(\text{x}_n)} = [\sum_{n - 1}^{N} {\phi(\text{x}_n) \phi(\text{x}_n)^T}] \text{w} \\ &amp; \Rightarrow \phi(\text{X})^T \text{t} = \phi(\text{X}) \phi(\text{X})^T \text{w} \\ &amp; \Rightarrow \hat{\text{w}} = (\phi(\text{X}) \phi(\text{X})^T)^{-1} \phi(\text{X}) \text{t} \end{align}<br>$$</p>
<p>Does it look familiar? It’s the same with LSR’s optimization result! We should have already got a better understanding about what Linear Squares Regression is. The LSR is equivalent to <a href="https://en.wikipedia.org/wiki/Maximum_likelihood" target="_blank" rel="external">Maximum Likelihood Estimation</a> under the assumption of Gaussian noise. Now let’s take a look at the previous mentioned \( \beta \). If we calculate the gradient w.r.t \( \beta \), we can get the optimization result like this (do it yourself :D):</p>
<p>$$<br>\frac{1} {\hat{\beta}} = \frac{1} {N} \sum_{n = 1}^{N} {[t_n - \hat{\text{w}}^T \phi(\text{x}_{n}) ]^2}<br>$$</p>
<p>The higher precision the \( \beta \) has, the lower mean squared error the data there would be. After getting these two values, we can predict new input with the following distribution:</p>
<p>$$<br>p(t | \text{x}, \hat{\text{w}}, \hat{\beta}) = \mathcal{N} \left( t | y(\text{x}, \hat{\text{w}}), \hat{\beta}^{-1} \right)<br>$$</p>
<p>So far, these illustrations are still based on the <a href="https://en.wikipedia.org/wiki/Frequentist_inference" target="_blank" rel="external">frequentist approach</a>, let’s now stride towards the Bayesian approaches.</p>
<h2 id="Probabilistic_Interpretation:_RR">Probabilistic Interpretation: RR</h2><p>Because of the equivalence between LSR and Maximum Likelihood Estimation under assumption of Gaussian noise, they also share the same challenge: overfitting. I have illustrated it in <a href="/2015/11/05/ML-Review-Least-Squares-Regression/">this post</a>. To avoid overfitting, in Ridge Regression, the regularization coefficient \( \lambda \) is involved to penalize the larger size weighting vectors. One way to get such \( \lambda \) is to take advantage of the empirical knowledge. So what is similar to “empirical knowledge” in probability field? The prior! Even so, it sounds quite abstract, let me illustrate it in formula.</p>
<p>Firstly I want to repeat our previous question again: Given a training set \( \text{X} \) and relative labels \( \text{t} \), our goal is to learn a single weighting vector \( \text{w} \), which “best” describes the data points. To avoid overfitting, we can provide some “guidance” to our model. Such “guidance” is a prior, which describes the prior distribution of the weighting vector \( \text{w} \). <strong>ATTENTION</strong>: it is the distribution of \( \text{w} \), rather than a single value of it.</p>
<p>Since it is a distribution, there must exist some parameters describing this distribution. We call such parameters the <a href="https://en.wikipedia.org/wiki/Hyperparameter" target="_blank" rel="external">hyperparameter</a>. For example, assume a given prior describing the \( \text{w} \) in Gaussian distribution. The hyperparameter \( \alpha = \left( m_{0}, S_{0} \right)\), where \( m_{0} \) is the mean, \( S_{0} \) is the variance. Therefore the distribution shall look like this:</p>
<p>$$<br>p(\text{w} | \alpha) = \mathcal{N} \left(\text{w} | m_{0}, S_{0} \text{I} \right) = \left( \frac{1} {2 \pi S_{0}} \right)^{(M + 1) / 2} \exp \left(- \frac{1} {2 S_{0}} (\text{w} - m_{0})^T (\text{w} - m_{0}) \right)<br>$$</p>
<p>Our posterior <strong>distribution</strong> over \( \text{w} \) is extended and according to the <a href="https://goo.gl/3K9Ymv" target="_blank" rel="external">Bayes’ Theorem</a>:</p>
<p>$$<br>p(\text{w} | \text{X}, \text{t}, \beta, \alpha) \propto p(\text{t} | \text{X}, \text{w}, \beta) p(\text{w} | \alpha)<br>$$</p>
<p>Minimizing its negative \( \log \) form:</p>
<p>$$<br>\begin{align} - \log {p(\text{w} | \text{X}, \text{t}, \beta, \alpha)} &amp; \propto - \log{p(\text{t} | \text{X}, \text{w}, \beta)} - \log{p(\text{w} | \alpha)} \\ &amp; \propto - \log{ \prod_{n = 1}^{N} {\mathcal{N} (t_n | y(\text{x}_n, \text{w}), \beta^{-1})} } - \log{ \exp \left(- \frac{1} {2 S_{0}} (\text{w} - m_{0})^T (\text{w} - m_{0}) \right) }  \\ &amp; \propto \frac{\beta}{2} \sum_{n = 1}^{N} \{ y(\text{x}_n, \text{w}) - t_n\}^2 + \frac{1} {2 S_0} (\text{w} - m_{0})^T (\text{w} - m_{0}) + \text{const} \\ &amp; \propto \frac{\beta}{2} \left( \text{w}^T \phi(\text{X}) - \text{t} \right)^2 + \frac{1} {2 S_0} (\text{w} - m_{0})^T (\text{w} - m_{0}) + \text{const} \end{align}<br>$$</p>
<p>Calculating the gradient we can get the optimized weighting vector \( \hat{\text{w}} \):</p>
<p>$$<br>\begin{align} \nabla_{\text{w}} \log {p(\text{t} | \text{X}, \text{w}, \beta, \alpha)} &amp; = - \beta \sum_{n = 1}^{N} {(t_n - \text{w}^T \phi(\text{x}_n)) \phi(\text{x}_n)} + {S_{0}}^{-1} (\text{w} - m_{0}) \stackrel{!}{=} 0 \\ &amp; \Rightarrow \beta \cdot \phi(\text{X})^T \text{t}  + {S_{0}}^{-1} m_{0} = \left( \beta \cdot \phi(\text{X}) \phi(\text{X})^T + {S_{0}}^{-1} \text{I} \right) \text{w} \\ &amp; \Rightarrow \hat{\text{w}} = \left( \beta \cdot \phi(\text{X}) \phi(\text{X})^T + {S_{0}}^{-1} \text{I} \right)^{-1} \left( \beta \cdot \phi(\text{X})^T \text{t}  + {S_{0}}^{-1} m_{0} \right) \end{align}<br>$$</p>
<p>The result looks quite complicated, but in general, for simplification, we often set the prior mean \( m_{0} = 0\). Then it will similar to the RR optimization result, and the regularization parameter \( \lambda \) in Ridge Regression will be equal to \( \frac{1} {S_{0} \beta} \). This is the so called <a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation" target="_blank" rel="external">Maximum a posteriori (MAP) estimation</a>.</p>
<h2 id="Summary">Summary</h2><p>So far, we have a better understanding to both of the ordinary linear regression (Least Squares Regression) and the regularized regression (Ridge Regression). The Least Squares Regression is equivalent to Maximum Likelihood Estimation under Gaussian noise assumption, and they share the same problem: overfitting. The Ridge Regression is equivalent to Maximum a Posterior estimation with a Gaussian prior distribution over weighting vector \( \text{w} \). The probabilistic interpretation to RR is already alike to the Bayesian estimation. In next post, I will try to introduce the Bayesian Curve Fitting. Hope it could help :D</p>
<h2 id="Reference">Reference</h2><p>[1] <a href="/2015/11/05/ML-Review-Least-Squares-Regression/">Least Squares Regression</a><br>[2] <a href="/2015/11/11/ML-Review-Ridge-Regression-and-Regularization/">Ridge Regression</a><br>[3] <a href="https://en.wikipedia.org/wiki/Maximum_likelihood" target="_blank" rel="external">Maximum Likelihood Estimation</a><br>[4] <a href="https://en.wikipedia.org/wiki/Frequentist_inference" target="_blank" rel="external">frequentist approach</a><br>[5] <a href="https://en.wikipedia.org/wiki/Hyperparameter" target="_blank" rel="external">hyperparameter</a><br>[6] <a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation" target="_blank" rel="external">Maximum a posteriori (MAP) estimation</a><br>[7] <a href="https://goo.gl/3K9Ymv" target="_blank" rel="external">Bayes’ Theorem</a><br>[8] Bishop, Christopher M. Pattern recognition and machine learning. springer, 2006.</p>
]]></content>
    <summary type="html">
    <![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript]]>
    </summary>
    
      <category term="Bayesian" scheme="http://tongsucn.com/tags/Bayesian/"/>
    
      <category term="Gaussian distribution" scheme="http://tongsucn.com/tags/Gaussian-distribution/"/>
    
      <category term="least squares regression" scheme="http://tongsucn.com/tags/least-squares-regression/"/>
    
      <category term="likelihood" scheme="http://tongsucn.com/tags/likelihood/"/>
    
      <category term="machine learning" scheme="http://tongsucn.com/tags/machine-learning/"/>
    
      <category term="maximum a posteriori" scheme="http://tongsucn.com/tags/maximum-a-posteriori/"/>
    
      <category term="maximum likelihood estimation" scheme="http://tongsucn.com/tags/maximum-likelihood-estimation/"/>
    
      <category term="posterior" scheme="http://tongsucn.com/tags/posterior/"/>
    
      <category term="prior" scheme="http://tongsucn.com/tags/prior/"/>
    
      <category term="probability interpretation" scheme="http://tongsucn.com/tags/probability-interpretation/"/>
    
      <category term="regression" scheme="http://tongsucn.com/tags/regression/"/>
    
      <category term="ridge regression" scheme="http://tongsucn.com/tags/ridge-regression/"/>
    
      <category term="tech" scheme="http://tongsucn.com/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[ML Review] Ridge Regression & Regularization]]></title>
    <link href="http://tongsucn.com/2015/11/11/ML-Review-Ridge-Regression-and-Regularization/"/>
    <id>http://tongsucn.com/2015/11/11/ML-Review-Ridge-Regression-and-Regularization/</id>
    <published>2015-11-11T10:18:52.000Z</published>
    <updated>2015-12-08T15:50:11.000Z</updated>
    <content type="html"><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript" async src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

<h2 id="Introduction">Introduction</h2><p>In the <a href="/2015/11/05/ML-Review-Least-Squares-Regression">previous post</a>, the Least Squares Regression (LSR) is reviewed. But the last shown example overfits when the frequency becomes higher (the basis function maps input points into higher dimensional feature space). This post will review a method called Ridge Regression against such overfitting. Furthermore, the concept of regularization will also be introduced.</p>
<h2 id="Ridge_Regression">Ridge Regression</h2><p>Before formally introduction to the Ridge Regression, let’s firstly think about, why overfitting happens in LSR. In our previous example, when frequency is \( 1 \), the trained function is not “flexible” enough. It can only express one pair of “wave crest” and “wave trough” within our training data’s range. Because of such limitation, the optimization have to compromise. Calculate a minimum error and getting a “trend description” as the final result.</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]LSR_3.png" width="256"></p>
<p>When the frequency increases to a larger number, the result functions become quite flexible. There are enough local “crest” and “trough” to fit the training points, which lead to local “trembling”, or in other words, overfitting. Our goal is now clear, we need to suppress such local “trembling” and keep its generally trend.</p>
<p>In our error function: \( E(\text{w}) = \left|\left| t - \text{w}^T \text{X} \right|\right|^2 \), with the increasement of basis function mapped feature space’s dimensional, the only changed thing is the weighting vector \( \text{w} \)’s dimension. If we penalize \( \text{w} \)’s size (number of dimension), results would be better: \( E_{ridge} (\text{w}) = \left|\left| t - \text{w}^T \text{X} \right|\right|^2 + \lambda \left|\left| \text{w} \right|\right|^2 \). Given a suitable \( \lambda \) (scalar, talk about its value selection later), higher \( \text{w} \) size will be penalized and “trembling” will be suppressed.</p>
<p>Not quite intuitive? Assume that \( \text{w}_{opt} \) is the optimized result from LSR error function \( E(\text{w}) \). But it could not be the minimum-value-point in Ridge Regression error function \( E_{ridge} (\text{w}) \) because of the insertion of \( \lambda \left|\left| \text{w}_{opt} \right|\right|^2 \). Therefore to achieve the minimum error value, the optimization procedure will adjust each component value in weighting vector \( \text{w} \). Let’s look at the comparison of variance (the table below). After observation we can find that the variance of components in each weighting vector decreased, which means the local “tremblings” are suppressed.</p>
<table>
<thead>
<tr>
<th style="text-align:center">frequency</th>
<th style="text-align:center">1</th>
<th style="text-align:center">3</th>
<th style="text-align:center">5</th>
<th style="text-align:center">7</th>
<th style="text-align:center">9</th>
<th style="text-align:center">11</th>
<th style="text-align:center">13</th>
<th style="text-align:center">15</th>
<th style="text-align:center">17</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">\( \lambda = 0 \) variance</td>
<td style="text-align:center">0.0342</td>
<td style="text-align:center">0.0774</td>
<td style="text-align:center">0.0551</td>
<td style="text-align:center">0.1171</td>
<td style="text-align:center">0.0532</td>
<td style="text-align:center">4.0241</td>
<td style="text-align:center">7.8691</td>
<td style="text-align:center">40.2198</td>
<td style="text-align:center">92.4461</td>
</tr>
<tr>
<td style="text-align:center">\( \lambda = 2 \) variance</td>
<td style="text-align:center">0.0323</td>
<td style="text-align:center">0.0610</td>
<td style="text-align:center">0.0387</td>
<td style="text-align:center">0.0289</td>
<td style="text-align:center">0.0227</td>
<td style="text-align:center">0.0187</td>
<td style="text-align:center">0.0160</td>
<td style="text-align:center">0.0139</td>
<td style="text-align:center">0.0123</td>
</tr>
<tr>
<td style="text-align:center">\( \lambda = 50 \) variance</td>
<td style="text-align:center">0.0122</td>
<td style="text-align:center">0.0096</td>
<td style="text-align:center">0.0060</td>
<td style="text-align:center">0.0043</td>
<td style="text-align:center">0.0034</td>
<td style="text-align:center">0.0028</td>
<td style="text-align:center">0.0024</td>
<td style="text-align:center">0.0021</td>
<td style="text-align:center">0.0018</td>
</tr>
</tbody>
</table>
<p>The penalizing from \( \lambda \) is reduced for a lower error. It will also be easy to imply:</p>
<p>$$<br>\begin{align} &amp; \lambda \rightarrow 0 &amp; \Rightarrow \ \ \ \ &amp; \text{w}_{ridge} \rightarrow \text{w}_{LSR} \\ &amp; \lambda \rightarrow \infty &amp; \Rightarrow \ \ \ \ &amp; \text{w}_{ridge} \rightarrow 0 \end{align}<br>$$</p>
<p>So everything should be clear, the optimization of \( E_{ridge} (\text{w}) \) is similar with the LSR (do the formula derivation yourself :D). Result should be:</p>
<p>$$<br>\hat{\text{w}} = (\text{X} \text{X}^T + \lambda \text{I})^{-1} \text{X} t<br>$$</p>
<p>Here is a <a href="https://github.com/tongsucn/MachineLearningPractice/blob/master/Regression/ridge_regression.py" target="_blank" rel="external">simple python implementation</a> and the MATLAB plot:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_train</span><span class="params">(self, freq)</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    Perform train on input training data.</span><br><span class="line">    Args:</span><br><span class="line">        freq: Frequency for Fourier basis function: scalar</span><br><span class="line">    Returns:</span><br><span class="line">        Result trained weight vector, numpy.ndarray: (2 * freq + 1) x 1</span><br><span class="line">    """</span></span><br><span class="line">    <span class="comment"># Mapping with basis function.</span></span><br><span class="line">    ext_pnt = self.fourier_basis(self.train_data, freq)</span><br><span class="line">    penalize = self.lam * np.eye(ext_pnt.shape[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculating and returning w.</span></span><br><span class="line">    weight = np.dot(np.transpose(ext_pnt), ext_pnt) + penalize</span><br><span class="line">    weight = np.dot(np.linalg.inv(weight), np.transpose(ext_pnt))</span><br><span class="line">    <span class="keyword">return</span> np.dot(weight, self.train_label)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_test</span><span class="params">(self, weight, freq, test_data, test_label)</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    Perform test on input testing data.</span><br><span class="line">    Args:</span><br><span class="line">        weight: The trained weight, numpy.ndarray: (2 * freq + 1) x 1</span><br><span class="line">        freq: The frequency for Fourier basis function: scalar</span><br><span class="line">        test_data: Test data points, numpy.ndarray: num x 1</span><br><span class="line">        test_label: Test data labels, numpy.ndarray: num x 1</span><br><span class="line">    Returns:</span><br><span class="line">        Test error, mean squared error is utilized: scalar</span><br><span class="line">    """</span></span><br><span class="line">    <span class="comment"># Mapping with basis function.</span></span><br><span class="line">    ext_pnt = self.fourier_basis(test_data, freq)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Testing and calculating error.</span></span><br><span class="line">    test_res = np.dot(ext_pnt, weight)</span><br><span class="line">    <span class="keyword">return</span> self._mse(test_res, test_label)</span><br></pre></td></tr></table></figure>
<p>As above mentioned, the result with lambda 0 shows the same result with LSR.</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]RR_1.png" width="256"></p>
<p>The result with lambda 2 looks much better, the overfitting problem is well suppressed and the generally trend is also preserved.</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]RR_2.png" width="256"></p>
<p>All the results with lambda 50 look similar. Although the overfitting problem is solved, but such suppression also causes a loss to precision.</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]RR_3.png" width="256"></p>
<h2 id="Regularization_and_Selection_of_\(_\lambda_\)">Regularization and Selection of \( \lambda \)</h2><p>Ridge Regression introduces a method to prevent overfitting. This method penalizes the size of weighting vector \( \text{w} \) with a suitable coefficient \( \lambda \). Such method, is called <a href="https://goo.gl/aR8UKA" target="_blank" rel="external">Regularization</a>. As above description, a “suitable” \( \lambda \) is the key to get a correct result. This chapter will introduce some information about regularization and the selection of \( \lambda \).</p>
<h3 id="Regularization">Regularization</h3><p><a href="https://goo.gl/aR8UKA" target="_blank" rel="external">Wikipedia</a>:</p>
<p><em>Regularization, in mathematics and statistics and particularly in the fields of machine learning and inverse problems, refers to a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting.</em></p>
<p>The most common “introduced information” in Machine Learning is appending a variable to the error function, which is composed of the penalizing coefficient and <a href="https://goo.gl/nKVaae" target="_blank" rel="external">L1-norm</a> or <a href="https://goo.gl/paVPK2" target="_blank" rel="external">L2-norm</a> form weighting vector. Our Ridge Regression use the L2-norm of the weighting vector.</p>
<p>Except Ridge Regression, there are also other methods utilizing the regularization. For example, <a href="http://statweb.stanford.edu/~tibs/lasso.html" target="_blank" rel="external">Lasso Regression</a>, which use L1-norm of weighting vector. (Maybe I would talk about it in the future posts)</p>
<h3 id="Selection_of_\(_\lambda_\)">Selection of \( \lambda \)</h3><p>Of course, the value of \( \lambda \) could be obtained by empirical knowledge, but this is not always the good choice (or we can just say it’s a bad idea).</p>
<p>A good solution is that trying \( \lambda \) with different values on some training sets and testing sets. But the problem is, in general, good training testing sets could be very expensive. Therefore, with one single training/test set, we can utilize the <a href="https://goo.gl/kesv1H" target="_blank" rel="external">cross-validation</a>.</p>
<p>Among different types of cross-validation, the most intuitive one is the “leave-one-out” cross-validation. At first, it equally divides the data sets into \( n \) subsets. Select one of these subsets as the test set, and the remaining subsets are the training sets. Doing the training/testing for n times (with different testing sets), then a relative more suitable \( \lambda \) value is obtained.</p>
<p>“Leave-one-out” cross-validation is a kind of <a href="https://goo.gl/wDEXjt" target="_blank" rel="external">exhaustive cross-validation</a>. There are still some non-exhaustive cross-validation like “k-fold” cross-validation.</p>
<h2 id="Summary">Summary</h2><p>Comparing with LSR, Ridge Regression with suitable penalizing on weighting vector \( \text{w} \)’s size can dramatically reduce the effect from overfitting. Such technique is called regularization. Hope they can help you :D</p>
<p>[1] <a href="https://github.com/tongsucn/MachineLearningPractice/blob/master/Regression/least_squares_regression.py" target="_blank" rel="external">Python code</a><br>[2] <a href="http://www.vision.rwth-aachen.de/teaching/advanced-machine-learning/winter-15-16/advanced-machine-learning" target="_blank" rel="external">Training &amp; Testing Data</a><br>[3] <a href="http://web.as.uky.edu/statistics/users/pbreheny/764-F11/notes/9-1.pdf" target="_blank" rel="external">Ridge Regression</a><br>[4] <a href="https://goo.gl/aR8UKA" target="_blank" rel="external">Regularization</a><br>[5] <a href="https://goo.gl/nKVaae" target="_blank" rel="external">L1-norm</a><br>[6] <a href="https://goo.gl/paVPK2" target="_blank" rel="external">L2-norm</a><br>[7] <a href="http://statweb.stanford.edu/~tibs/lasso.html" target="_blank" rel="external">Lasso Regression</a><br>[8] <a href="https://goo.gl/BKKNg5" target="_blank" rel="external">Cross-validation</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript]]>
    </summary>
    
      <category term="algorithms" scheme="http://tongsucn.com/tags/algorithms/"/>
    
      <category term="machine learning" scheme="http://tongsucn.com/tags/machine-learning/"/>
    
      <category term="regression" scheme="http://tongsucn.com/tags/regression/"/>
    
      <category term="regularization" scheme="http://tongsucn.com/tags/regularization/"/>
    
      <category term="ridge regression" scheme="http://tongsucn.com/tags/ridge-regression/"/>
    
      <category term="tech" scheme="http://tongsucn.com/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[[ML Review] Least Squares Regression]]></title>
    <link href="http://tongsucn.com/2015/11/05/ML-Review-Least-Squares-Regression/"/>
    <id>http://tongsucn.com/2015/11/05/ML-Review-Least-Squares-Regression/</id>
    <published>2015-11-05T21:32:20.000Z</published>
    <updated>2015-11-24T09:38:14.000Z</updated>
    <content type="html"><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript" async src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>

<h2 id="Introduction">Introduction</h2><p>In machine learning, regression is utilized to predict continuous values. Least squares regression is one of the simplest regression technology. Given the training set: \( \text{X} = \{x_1, …, x_N\} \) with target values \( T = \{t_1, …, t_N\} \). Our goal is to obtain a function, which can “best” describe these points and predict other input points’ target values. But how can we obtain such a function?</p>
<h2 id="Linear">Linear</h2><p>Firstly, we need to “guess” the form of this function. The simplest is the linear function: \( y = kx + b \), just like what we have learnt in middle school. Let’s write it as \( t = w \cdot x + w_0 \), where \(t\) is the target value, \(w\) is the weight and \(w_0\) is bias. Therefore, to get this function, our goal now becomes calculating the value of \(w\) and \(w_0\).</p>
<p>It is obvious that we need to use some points to calculate the weight and bias. Such points named training sets. In general, training sets contain two parts: some data points \(\text{X} = [x_1, …, x_N] \) and their labels (or target values) \( t = [t_1, …, t_N] \). The formula becomes \( w^T \text{X} + w_0 = t \). In most cases we can write it as \( \widetilde{\text{w}}^T \widetilde{\text{X}} = t \), where \( \widetilde{\text{w}} = [w, w_0]^T \), \( \widetilde{\text{X}} = [\widetilde{x}_1, …, \widetilde{x}_N] \) and \( {\widetilde{x}}_i = [x_i, 1]^T \).</p>
<p>How to calculate \( \widetilde{\text{w}} \) now? Let’s consider about it from another perspective. If a suitable \( \widetilde{\text{w}} \) is given, we can easily calculate a set of labels \( t^\prime \) for the above training set \( \widetilde{\text{X}} \). But in general the components in \( t - t^\prime \) cannot be zero because the points don’t always (or we can say never) fit perfectly. (See the picture below, click to enlarge)</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]LSR_1.png" width="256"></p>
<p>In other words, if there exists a \( \widetilde{\text{w}} \), which makes the difference between \( t^\prime \) and \( t \) minimal, then this linear function with \( \widetilde{\text{w}} \) can “best” describe these points. Such \( \widetilde{\text{w}} \) is what we want. Therefore we can get it via computing the derivative of error function \( E(\widetilde{\text{w}}) = \left|\left| \widetilde{\text{w}}^T \widetilde{\text{X}}- t \right|\right|^2  \):</p>
<p>$$<br>\begin{align} &amp;&amp; \frac{\partial E(\widetilde{\text{w}})}{\partial \widetilde{\text{w}}} &amp; = 2 \widetilde{\text{X}} (\widetilde{\text{w}}^T \widetilde{\text{X}} - t) \stackrel{!}{=} 0 \\ &amp; \Rightarrow &amp; \widetilde{\text{X}} \widetilde{\text{X}}^T \widetilde{\text{w}} &amp; = \widetilde{\text{X}} t \\ &amp; \Rightarrow &amp; \quad \widetilde{\text{w}} &amp; = (\widetilde{\text{X}} \widetilde{\text{X}}^T)^{-1} \widetilde{\text{X}} t \end{align}<br>$$</p>
<p>The <a href="https://github.com/tongsucn/MachineLearningPractice/blob/master/Regression/least_squares_regression.py" target="_blank" rel="external">Python code</a>. (Python 3 + numpy)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">training_data_point = ...</span><br><span class="line">training_data_label = ...</span><br><span class="line">training_data_num = ...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lsr_train</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    Training least squares regression (linear).</span><br><span class="line">    Returns:</span><br><span class="line">        The weights w (2 x 1).</span><br><span class="line">    """</span></span><br><span class="line">    <span class="comment"># Extending data points with an additional dimensional of value one</span></span><br><span class="line">    ext_points = ext_data(training_data_point, training_data_num)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculating and returning w</span></span><br><span class="line">    res_w = np.dot(ext_points, np.transpose(ext_points))</span><br><span class="line">    res_w = np.dot(np.linalg.inv(res_w), ext_points)</span><br><span class="line">    <span class="keyword">return</span> np.dot(res_w, np.transpose(training_data_label))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ext_data</span><span class="params">(target_data, length, axis=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    Extending data points with an additional dimension of value one.</span><br><span class="line">    Args:</span><br><span class="line">        target_data: The 1-D data points to be extended (num x 1).</span><br><span class="line">        length: The number of input data points (scalar).</span><br><span class="line">        axis: The dimension to be extended, 0 by default.</span><br><span class="line">    Returns:</span><br><span class="line">        The extended data points (num x 2).</span><br><span class="line">    """</span></span><br><span class="line">    one = np.ones((length, <span class="number">1</span>)) <span class="keyword">if</span> axis <span class="keyword">else</span> np.ones((<span class="number">1</span>, length))</span><br><span class="line">    <span class="keyword">return</span> np.concatenate((target_data, one), axis)</span><br></pre></td></tr></table></figure>
<p>Let’s see its result on a given training set:</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]LSR_2.png" width="256"></p>
<h2 id="Non-linear">Non-linear</h2><p>Although the obtained line describes the trend of these <a href="https://github.com/tongsucn/MachineLearningPractice/blob/master/Regression/regTrain.txt" target="_blank" rel="external">data points</a>, but it’s not what we want. Why? Because it doesn’t fit the points well, our function is linear but the data points implies a non-linear model! Our “guess” is not suitable for this case. So the solution should be clear: using some non-linear functions instead of the pure linear one, e.g. in polynomial form like \(t = ax^2 + bx + c\) (of course this function is not suitable for the above case, it’s just an example :P), or in Fourier form like \(t = \cos{(2 \pi x)} + \sin{(2 \pi x)} + 1\).</p>
<p>There could be many different forms of such non-linear functions, but for convenience, we need to unify them into a linear form: \(t = \text{w}^T \phi{(\text{X})}\). The \(\phi\) here is the so called <a href="https://en.wikipedia.org/wiki/Basis_function" target="_blank" rel="external">basis function</a>, it maps our points (1-D in our case) into a non-linear form for example \(\phi{(x)} = (1, x, x^2)^T\). The weight \(\text{w}\) now should be in form of \((w_0, w_1, w_2)^T\). In this case, our function will look like \(t = \text{w}^T \phi{(\text{X})} = w_0 + w_1 x + w_2 x^2\), where \(w_0\) is the bias (so the basis function should provide a \(1\) component for the bias in the result like ours). It’s now in non-linear form! Let’s perform it on our data with basis function:</p>
<p>$$ \phi{(x)} = (\phi_{0} (x), \phi_{1} (x), \phi_{2} (x), …) $$</p>
<p>where</p>
<p>$$<br>\begin{align} \phi_{0} (x) &amp; = 1 \\  \phi_{2n - 1} (x) &amp; = \frac{\cos{(2 \pi nx)}}{n} \\ \phi_{2n} (x) &amp; = \frac{\sin{(2 \pi nx)}}{n} \end{align}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lsr_train</span><span class="params">(freq)</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    Training least squares regression (non-linear).</span><br><span class="line">    Returns:</span><br><span class="line">        The weights w ((2 x freq + 1) x 1).</span><br><span class="line">    """</span></span><br><span class="line">    <span class="comment"># Extending data points with an additional dimensional of value one</span></span><br><span class="line">    ext_points = basis_function(training_data_point, training_data_num, freq)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculating and returning w</span></span><br><span class="line">    res_w = np.dot(ext_points, np.transpose(ext_points))</span><br><span class="line">    res_w = np.dot(np.linalg.inv(res_w), ext_points)</span><br><span class="line">    <span class="keyword">return</span> np.dot(res_w, np.transpose(training_data_label))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">basis_func</span><span class="params">(input_data, data_num, freq)</span>:</span></span><br><span class="line">    <span class="string">"""</span><br><span class="line">    Mapping 1-D data points using basis function</span><br><span class="line">    Args:</span><br><span class="line">        input_data: The 1-D data points (1 x data_num).</span><br><span class="line">        data_num: The number of input data points (scalar).</span><br><span class="line">        freq: The frequency, used to calculate components number (scalar).</span><br><span class="line">    Returns:</span><br><span class="line">        The mapped data points ((2 x freq + 1) x data_num).</span><br><span class="line">    """</span></span><br><span class="line">    nf_points = np.ndarray((<span class="number">2</span> * freq + <span class="number">1</span>, data_num))</span><br><span class="line">    nf_points[<span class="number">0</span>, :] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, freq + <span class="number">1</span>):</span><br><span class="line">        nf_points[<span class="number">2</span> * k - <span class="number">1</span>, :] = np.cos(<span class="number">2</span> * np.pi * k * input_data) / k</span><br><span class="line">        nf_points[<span class="number">2</span> * k, :] = np.sin(<span class="number">2</span> * np.pi * k * input_data) / k</span><br><span class="line">    <span class="keyword">return</span> nf_points</span><br></pre></td></tr></table></figure>
<p>Let’s see the results with different \( n \) values (i.e. different frequency values).</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]LSR_3.png" width="256"></p>
<p>At \( n = 1 \), the curve fits the trianing points not bad. When it increases to \( 3 \) and \( 5 \), the fitting looks much better. But after \( n = 7 \), things become out of control. The curves begin to “tremble” locally, they seem to try to fit every point in the training set. As a human, we definitely know that the correct result should look like the \( n = 3\) or \( n = 5 \) cases. That is, if we give the curve of \( n = 17 \) some test points, the curve will output worse results than the \( n = 3 \) or \( n = 5 \) cases, although it could better fit the training points. Such situation is called <a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank" rel="external">overfittting</a>.</p>
<p>The comparison of training and testing error rate is shown in the belowing picture. The <a href="https://en.wikipedia.org/wiki/Mean_squared_error" target="_blank" rel="external">mean squared error</a> is utilized here. It’s obvious that training MSE decreased all the time, but testing MSE experienced decreasement firstly, then dramatically increased.</p>
<p><img src="http://7xo3hd.com1.z0.glb.clouddn.com/[ML_Review]LSR_4.png" width="256"></p>
<h2 id="Summary">Summary</h2><p>Therefore, in least squares regression, more complex models (e.g. larger \( n \)) don’t always mean better predication results. Both selection of basis function and overfitting are challenges. I will review a solution to overfitting of least squares regression in next article. Some more general methods will also be introduced in the future. Hope they can help you :D</p>
<h2 id="Reference">Reference</h2><p>[1] <a href="https://github.com/tongsucn/MachineLearningPractice/blob/master/Regression/least_squares_regression.py" target="_blank" rel="external">Python code</a><br>[2] <a href="http://www.vision.rwth-aachen.de/teaching/advanced-machine-learning/winter-15-16/advanced-machine-learning" target="_blank" rel="external">Training &amp; Testing Data</a><br>[3] <a href="https://en.wikipedia.org/wiki/Basis_function" target="_blank" rel="external">Basis function</a><br>[4] <a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank" rel="external">Overfitting</a><br>[5] <a href="https://en.wikipedia.org/wiki/Mean_squared_error" target="_blank" rel="external">Mean Squared Error</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({tex2jax: {inlineMath: [['\\(', '\\)']]}});
</script>
<script type="text/javascript]]>
    </summary>
    
      <category term="algorithms" scheme="http://tongsucn.com/tags/algorithms/"/>
    
      <category term="basis function" scheme="http://tongsucn.com/tags/basis-function/"/>
    
      <category term="least squares regression" scheme="http://tongsucn.com/tags/least-squares-regression/"/>
    
      <category term="machine learning" scheme="http://tongsucn.com/tags/machine-learning/"/>
    
      <category term="mean squared error" scheme="http://tongsucn.com/tags/mean-squared-error/"/>
    
      <category term="regression" scheme="http://tongsucn.com/tags/regression/"/>
    
      <category term="tech" scheme="http://tongsucn.com/categories/tech/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[First Post]]></title>
    <link href="http://tongsucn.com/2015/03/06/First-Post/"/>
    <id>http://tongsucn.com/2015/03/06/First-Post/</id>
    <published>2015-03-06T08:30:20.000Z</published>
    <updated>2015-10-30T10:45:13.000Z</updated>
    <content type="html"><![CDATA[<p>Hello world!</p>
<p>This is my new blog. I will begin to record my life and study here. My interest are Computer Vision and Machine Learning.</p>
<p>It will be greatly honoured if my words here could help you.</p>
<p>Tong Su</p>
<p>MathJax Test:</p>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<p>$$E=mc^2$$</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Hello world!</p>
<p>This is my new blog. I will begin to record my life and study here. My interest are Computer Vision and Machine Learn]]>
    </summary>
    
      <category term="blog" scheme="http://tongsucn.com/categories/blog/"/>
    
  </entry>
  
</feed>